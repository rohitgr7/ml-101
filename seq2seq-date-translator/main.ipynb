{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from faker import Faker\n",
    "import babel\n",
    "from babel.dates import format_date\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_FORMATS = ['short',\n",
    "           'medium',\n",
    "           'long',\n",
    "           'full',\n",
    "           'd MMM YYY',\n",
    "           'd MMMM YYY',\n",
    "           'dd MMM YYY',\n",
    "           'd MMM, YYY',\n",
    "           'd MMMM, YYY',\n",
    "           'dd, MMM YYY',\n",
    "           'd MM YY',\n",
    "           'd MMMM YYY',\n",
    "           'MMMM d YYY',\n",
    "           'MMMM d, YYY',\n",
    "           'dd.MM.YY',\n",
    "           ]\n",
    "\n",
    "LOCALES = babel.localedata.locale_identifiers()\n",
    "LOCALES = [lang for lang in LOCALES if 'en' in str(lang)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateGenerator():\n",
    "    \n",
    "    def __init__(self, LOCALES,  DATE_FORMATS, size):\n",
    "        self.LOCALES = LOCALES\n",
    "        self.DATE_FORMATS = DATE_FORMATS\n",
    "        self.size = size\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        \n",
    "    def load_data(self):\n",
    "        _fake = Faker()\n",
    "        random.seed(101)\n",
    "        random.seed(101)\n",
    "        \n",
    "        for i in range(self.size):\n",
    "            date = _fake.date_object()\n",
    "            gen_date = format_date(date, format=random.choice(self.DATE_FORMATS), locale = random.choice(self.LOCALES))\n",
    "            machine_date = date.isoformat()\n",
    "            self.x.append(gen_date)\n",
    "            self.y.append(machine_date)\n",
    "        \n",
    "        return self.x, self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_gen = DateGenerator(LOCALES, DATE_FORMATS, 50000)\n",
    "x, y = date_gen.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chars = set(''.join(x))\n",
    "x_char_to_ix = dict(zip(x_chars, range(len(x_chars))))\n",
    "\n",
    "y_chars = set(''.join(y))\n",
    "y_char_to_ix = dict(zip(y_chars, range(len(y_chars))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "x_char_to_ix['<PAD>'] = len(x_char_to_ix)\n",
    "x_ix_to_char = {i:char for char, i in x_char_to_ix.items()}\n",
    "max_len = max([len(char) for char in x])\n",
    "x_vec = [[x_char_to_ix['<PAD>']]*(max_len - len(date)) + [x_char_to_ix[char] for char in date] for date in x]\n",
    "x_vec = np.array(x_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <GO> Padding\n",
    "y_char_to_ix['<GO>'] = len(y_char_to_ix)\n",
    "y_ix_to_char = {i:char for char, i in y_char_to_ix.items()}\n",
    "y_vec = [[y_char_to_ix['<GO>']] + [y_char_to_ix[char] for char in date] for date in y]\n",
    "y_vec = np.array(y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(x, y, batch_size):\n",
    "    shuffle = np.random.permutation(len(x))\n",
    "    start = 0\n",
    "    x = x[shuffle]\n",
    "    y = y[shuffle]\n",
    "    \n",
    "    while start + batch_size <= len(x) :\n",
    "        yield x[start:start + batch_size], y[start:start + batch_size]\n",
    "        start = (start + batch_size) % len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq = len(x_vec[0])\n",
    "y_seq = len(y_vec[0]) - 1\n",
    "input_len = len(x_char_to_ix)\n",
    "output_len = len(y_char_to_ix)\n",
    "lstm_units = 32\n",
    "batch_size = 128\n",
    "\n",
    "embed_size = 10\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# PLACEHOLDERS\n",
    "inputs = tf.placeholder(tf.int32, shape = [None, x_seq], name = 'inputs')\n",
    "dec_inputs = tf.placeholder(tf.int32, shape = [None, None], name = 'dec_inputs')\n",
    "targets = tf.placeholder(tf.int32, shape = [None, None], name = 'targets')\n",
    "\n",
    "\n",
    "# EMBEDDINGS\n",
    "input_embed = tf.Variable(tf.random_uniform([input_len, embed_size], -1, 1), name = 'input_embed')\n",
    "output_embed = tf.Variable(tf.random_uniform([output_len, embed_size], -1, 1), name = 'output_embed')\n",
    "\n",
    "input_date_embed = tf.nn.embedding_lookup(input_embed, inputs)\n",
    "dec_inputs_date_embed = tf.nn.embedding_lookup(output_embed, dec_inputs)\n",
    "\n",
    "\n",
    "# ENCODER\n",
    "with tf.variable_scope('encoder'):\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(lstm_units)\n",
    "    _, last_state = tf.nn.dynamic_rnn(lstm_cell, inputs = input_date_embed, dtype = tf.float32)\n",
    "\n",
    "    \n",
    "# DECODER\n",
    "with tf.variable_scope('decoder'):\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(lstm_units)\n",
    "    decoder_outputs, _ = tf.nn.dynamic_rnn(lstm_cell, inputs = dec_inputs_date_embed, initial_state = last_state, dtype = tf.float32)\n",
    "    \n",
    "\n",
    "# FINAL LAYER\n",
    "logits = tf.layers.dense(decoder_outputs, output_len)\n",
    "\n",
    "\n",
    "# LOSS and OPTIMIZER\n",
    "loss = tf.contrib.seq2seq.sequence_loss(logits, targets, weights = tf.ones([batch_size, y_seq]))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 1e-3)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# ACCURACY\n",
    "y_pred = tf.argmax(logits, axis = -1)\n",
    "matches = tf.equal(tf.cast(y_pred, dtype = tf.int32), tf.cast(targets, dtype = tf.int32))\n",
    "accuracy = tf.reduce_mean(tf.cast(matches, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(x_vec.shape[0] * 0.7)\n",
    "X_train, y_train = x_vec[:train_size], y_vec[:train_size]\n",
    "X_test, y_test = x_vec[train_size:], y_vec[train_size:]\n",
    "\n",
    "num_epochs = 10\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Time:  7.608\n",
      "---- Loss:  1.487 \t Training Accuracy:  0.505\n",
      "\n",
      "\n",
      "Epoch: 2 \t Time:  7.101\n",
      "---- Loss:  0.776 \t Training Accuracy:  0.734\n",
      "\n",
      "\n",
      "Epoch: 3 \t Time:  7.128\n",
      "---- Loss:  0.519 \t Training Accuracy:  0.840\n",
      "\n",
      "\n",
      "Epoch: 4 \t Time:  7.097\n",
      "---- Loss:  0.357 \t Training Accuracy:  0.895\n",
      "\n",
      "\n",
      "Epoch: 5 \t Time:  7.114\n",
      "---- Loss:  0.252 \t Training Accuracy:  0.928\n",
      "\n",
      "\n",
      "Epoch: 6 \t Time:  7.300\n",
      "---- Loss:  0.182 \t Training Accuracy:  0.949\n",
      "\n",
      "\n",
      "Epoch: 7 \t Time:  7.163\n",
      "---- Loss:  0.137 \t Training Accuracy:  0.961\n",
      "\n",
      "\n",
      "Epoch: 8 \t Time:  7.198\n",
      "---- Loss:  0.106 \t Training Accuracy:  0.970\n",
      "\n",
      "\n",
      "Epoch: 9 \t Time:  7.288\n",
      "---- Loss:  0.085 \t Training Accuracy:  0.977\n",
      "\n",
      "\n",
      "Epoch: 10 \t Time:  7.317\n",
      "---- Loss:  0.069 \t Training Accuracy:  0.982\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        training_accuracy = 0\n",
    "        training_loss = 0\n",
    "        i = 0\n",
    "        for batch_x, batch_y in generate_batch(X_train, y_train, batch_size):\n",
    "            i += 1\n",
    "            batch_accuracy, batch_loss, _= sess.run([accuracy, loss, train], feed_dict = {inputs: batch_x, dec_inputs: batch_y[:, :-1], targets: batch_y[:, 1:]})\n",
    "            training_loss += batch_loss\n",
    "            training_accuracy += batch_accuracy\n",
    "            \n",
    "        training_loss /= i\n",
    "        training_accuracy /= i\n",
    "        print('Epoch: {} \\t Time: {:>6.3f}'.format(epoch+1, time.time() - start_time))\n",
    "        print('---- Loss: {:>6.3f} \\t Training Accuracy: {:>6.3f}'.format(training_loss, training_accuracy))\n",
    "        print('\\n')        \n",
    "        \n",
    "    saver.save(sess, 'models/model-{}.ckpt'.format(num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/model-10.ckpt\n",
      "Test Accuracy:  0.977\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "test_batch_x, test_batch_y = next(generate_batch(X_test, y_test, batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'models/model-{}.ckpt'.format(num_epochs))\n",
    "    dec_input = np.zeros((batch_size, 1)) + y_char_to_ix['<GO>']\n",
    "    \n",
    "    for i in range(y_seq):\n",
    "        batch_logits = sess.run(logits, feed_dict = {inputs: test_batch_x, dec_inputs: dec_input})\n",
    "        pred = batch_logits[:, -1].argmax(axis = -1).reshape(-1, 1)\n",
    "        dec_input = np.hstack([dec_input, pred])\n",
    "\n",
    "    print('Test Accuracy: {:>6.3f}'.format(np.mean(dec_input == test_batch_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### END ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
