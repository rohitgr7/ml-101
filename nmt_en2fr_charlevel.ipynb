{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_en2fr_charlevel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "FR2qnAKdT0Wl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Basic characted level rnn for nmt of English to French\n",
        "### Dataset: [Link](http://www.manythings.org/anki/)"
      ]
    },
    {
      "metadata": {
        "id": "mURGqN3o8Nyt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dcg6Xt0O9ZRV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d_path = './data/fra.txt'\n",
        "batch_size=64\n",
        "epochs=100\n",
        "hidden_dim=256\n",
        "num_samples=10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TFCYU_zRcl6Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read and preprocess data"
      ]
    },
    {
      "metadata": {
        "id": "9YwIuWquNv1g",
        "colab_type": "code",
        "outputId": "456c4292-1170-4437-ee50-d34498433271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with open(d_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "   \n",
        "print(len(lines))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "160873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7tCzVHsHN_iQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inp_texts = []\n",
        "target_texts = []\n",
        "inp_chars = set()\n",
        "target_chars = set()\n",
        "\n",
        "for txt in lines[:min(num_samples, len(lines)-1)]:\n",
        "    inp_txt, target_txt = txt.split('\\t')\n",
        "    # Since this is character level so we can only add one character as start and end token\n",
        "    target_txt = '<' + target_txt + '>'\n",
        "    inp_texts.append(inp_txt)\n",
        "    target_texts.append(target_txt)\n",
        "    \n",
        "    for ch in inp_txt:\n",
        "        inp_chars.add(ch)\n",
        "    for ch in target_txt:\n",
        "        target_chars.add(ch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "voldoDojOKpo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mappings\n",
        "enc_ch2ix = {ch:i for i, ch in enumerate(inp_chars)}\n",
        "enc_ix2ch = {i:ch for ch, i in enc_ch2ix.items()}\n",
        "dec_ch2ix = {ch:i for i, ch in enumerate(target_chars)}\n",
        "dec_ix2ch = {i:ch for ch, i in dec_ch2ix.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CHmnmduFUMf1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_data(texts, vocab_size, mapping, mode='post'):\n",
        "    max_len = max([len(txt) for txt in texts])\n",
        "    data = np.zeros(shape=(len(texts), max_len, vocab_size))\n",
        "    \n",
        "    for i, txt in enumerate(texts):\n",
        "        for t, ch in enumerate(txt):\n",
        "            if mode == 'post':\n",
        "                data[i, t, mapping[ch]] = 1\n",
        "            elif mode == 'pre':\n",
        "                t_minus = max_len - len(txt) + t\n",
        "                data[i, t_minus, mapping[ch]] = 1\n",
        "          \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rj66tWdpW3Ru",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "enc_len = len(inp_chars)\n",
        "dec_len = len(target_chars)\n",
        "enc_inp = create_data(inp_texts, enc_len, enc_ch2ix, mode='pre')\n",
        "dec_inp = create_data(target_texts, dec_len, dec_ch2ix)\n",
        "dec_target = np.zeros_like(dec_inp)\n",
        "dec_target[:, :-1, :] = dec_inp[:, 1:, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRGKYGbMaN10",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training model"
      ]
    },
    {
      "metadata": {
        "id": "7kwIvKlzcaxW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape=(None, enc_len))\n",
        "encoder = LSTM(hidden_dim, return_state=True)\n",
        "encoder_outputs, encoder_state_h, encoder_state_c = encoder(encoder_inputs)\n",
        "encoder_states = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, dec_len))\n",
        "decoder = LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(dec_len, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
        "model.compile(optimizer = 'rmsprop', loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l216DNlrAaYa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "10e1f30f-002e-4da5-8ac1-2c354615d37e"
      },
      "cell_type": "code",
      "source": [
        "model.fit([enc_inp, dec_inp], dec_target, batch_size=batch_size, epochs=10, validation_split=0.2)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/10\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.3769 - val_loss: 0.4857\n",
            "Epoch 2/10\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.3610 - val_loss: 0.4801\n",
            "Epoch 3/10\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.3464 - val_loss: 0.4760\n",
            "Epoch 4/10\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.3325 - val_loss: 0.4729\n",
            "Epoch 5/10\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.3191 - val_loss: 0.4636\n",
            "Epoch 6/10\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.3071 - val_loss: 0.4644\n",
            "Epoch 7/10\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.2952 - val_loss: 0.4612\n",
            "Epoch 8/10\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.2842 - val_loss: 0.4617\n",
            "Epoch 9/10\n",
            "8000/8000 [==============================] - 23s 3ms/step - loss: 0.2737 - val_loss: 0.4579\n",
            "Epoch 10/10\n",
            "8000/8000 [==============================] - 22s 3ms/step - loss: 0.2638 - val_loss: 0.4636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a0ca70ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "metadata": {
        "id": "RJISPn7rfk-x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inference Model"
      ]
    },
    {
      "metadata": {
        "id": "4mNWWIJxg7NK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs = encoder_states)\n",
        "\n",
        "decoder_input_state_h = Input(shape=(hidden_dim,))\n",
        "decoder_input_state_c = Input(shape=(hidden_dim,))\n",
        "decoder_state_inputs = [decoder_input_state_h, decoder_input_state_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(inputs = [decoder_inputs] + decoder_state_inputs, outputs = [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EGRUYH8Kjb-j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def translate(txt):\n",
        "    enc_txt = create_data([txt], enc_len, enc_ch2ix, mode='pre')\n",
        "    target_seq = np.zeros((1, 1, dec_len))\n",
        "    target_seq[0, 0, dec_ch2ix['<']] = 1\n",
        "\n",
        "    dec_states = encoder_model.predict(enc_txt)\n",
        "    \n",
        "    decoded = ''\n",
        "    \n",
        "    while True:\n",
        "        # Call the decoder output\n",
        "        dec_out, h, c = decoder_model.predict([target_seq] + dec_states)\n",
        "        dec_states = [h, c]\n",
        "        \n",
        "        # Get the max token\n",
        "        token = np.argmax(dec_out[0, 0])\n",
        "        token_ch = dec_ix2ch[np.argmax(dec_out[0, 0])]\n",
        "\n",
        "        if token_ch == '>' or len(decoded) > dec_len:\n",
        "            break\n",
        "        \n",
        "        # Add the token and update the target_seq\n",
        "        decoded += token_ch\n",
        "        target_seq = np.zeros((1, 1, dec_len))\n",
        "        target_seq[0, 0, token] = 1\n",
        "    \n",
        "    return decoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fx3IzuIG9gjb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_samples(texts = inp_texts, trans_texts = target_texts, n_samples = 10):\n",
        "    N = len(inp_texts)\n",
        "    rand_ix = np.random.randint(0, N, n_samples)\n",
        "    \n",
        "    for i in rand_ix:\n",
        "        txt = inp_texts[i]\n",
        "        decoded = translate(txt)\n",
        "        print(f'Text: {txt}')\n",
        "        print(f'Target: {trans_texts[i][1:-1]}')\n",
        "        print(f'Prediction: {decoded}')\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7WqrGUCh-2_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "38a7dcff-d915-44dd-f75c-f9f0f9d20ce4"
      },
      "cell_type": "code",
      "source": [
        "generate_samples()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: They got it.\n",
            "Target: Ils l'ont eu.\n",
            "Prediction: Elles ont des noussas.\n",
            "\n",
            "Text: Who's that boy?\n",
            "Target: Qui est ce garçon ?\n",
            "Prediction: Qui est eu vieux ?\n",
            "\n",
            "Text: I serve no one.\n",
            "Target: Je ne suis au service de personne.\n",
            "Prediction: Je vous ai sauvées entrer.\n",
            "\n",
            "Text: He is an actor.\n",
            "Target: C'est un acteur.\n",
            "Prediction: Il est en train de manger.\n",
            "\n",
            "Text: The girls won.\n",
            "Target: Les filles gagnèrent.\n",
            "Prediction: Il est mon tourna.\n",
            "\n",
            "Text: I'll need this.\n",
            "Target: Je vais avoir besoin de ceci.\n",
            "Prediction: Je veux le chancer.\n",
            "\n",
            "Text: I'll marry you.\n",
            "Target: Je t'épouserai.\n",
            "Prediction: Je veux le trander.\n",
            "\n",
            "Text: They're there.\n",
            "Target: Ils sont là.\n",
            "Prediction: Ils sont diventes.\n",
            "\n",
            "Text: I love my home.\n",
            "Target: J'adore mon chez-moi.\n",
            "Prediction: J'adore les ffaires.\n",
            "\n",
            "Text: Cows give milk.\n",
            "Target: Les vaches donnent du lait.\n",
            "Prediction: Les chaches conne nous ai sais de marrire.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ADmOL6DDOtAO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Since it is just character level rnn it is giving some good results after 10 epochs only, but is overfitting after 10 epochs."
      ]
    },
    {
      "metadata": {
        "id": "sAUmTBN5TWHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}